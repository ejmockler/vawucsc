# robots.txt - for an explanation, see:
#   http://www.robotstxt.org/
#   http://en.wikipedia.org/wiki/Robots_exclusion_standard

# For all sites
User-agent: *
Disallow: /cgi-bin/		# cgi-bin scripts
Disallow: /include/		# include directory
Disallow: /private/		# private directory
Disallow: /test/		# test directory
Disallow: /weblog/		# weblog report directory

# Works only for some spiders (e.g. MSN)
User-agent: *
Crawl-delay: 5			# Wait 5 seconds between requests
